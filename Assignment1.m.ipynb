{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import numpy.matlib\n",
    "# didnt work ??? import functions.py.ipynb as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loades an entire batch\n",
    "def LoadBatch(filename):\n",
    "\t\"\"\" Copied from the dataset website \"\"\" \n",
    "\twith open('Datasets/'+filename, 'rb') as fo:\n",
    "\t\tdict = pickle.load(fo, encoding='bytes') \n",
    "\treturn dict\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\" Standard definition of the softmax function \"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def ReadData(filename):\n",
    "    data_batch = LoadBatch(filename)\n",
    "    \n",
    "    # get pixel data\n",
    "    pixel_data = data_batch[b'data']\n",
    "    # labels for each image\n",
    "    labels = data_batch[b'labels']\n",
    "    # one-hot rep. of labels\n",
    "    one_hot = np.eye(10)[labels]\n",
    "    return pixel_data, one_hot, labels\n",
    "\n",
    "def GetMeanAndStd(data):  \n",
    "    print(data)\n",
    "    # Kanske ändra\n",
    "    mean = np.mean(data, 0)\n",
    "    std = np.std(data, 0) # nånting saknas \n",
    "    return mean, std\n",
    "\n",
    "# input trainings data mean std\n",
    "def Normalize(train, validation, test, mean, std):\n",
    "        # convert to floar\n",
    "        train = np.float64(train)\n",
    "        validation = np.float64(validation)\n",
    "        test = np.float64(test)\n",
    "        \n",
    "        # Lurigt\n",
    "        train -= mean \n",
    "        train /= std\n",
    "    \n",
    "        validation -= mean\n",
    "        validation /= std\n",
    "        \n",
    "        test -= mean\n",
    "        test /= std\n",
    "        \n",
    "        return train, validation, test\n",
    "        \n",
    "        #train = train    \n",
    "def GetWeightAndBias(X, Y):\n",
    "    W_size = np.shape(X)\n",
    "    b_size = np.shape(Y)\n",
    "\n",
    "    # loc = mean, scale = std\n",
    "    W = np.random.normal(loc=0.0, scale=0.01, size=W_size)\n",
    "    b = np.random.normal(loc=0.0, scale=0.01, size=b_size[0])\n",
    "    \n",
    "    return W, b\n",
    "\n",
    "def EvaluateClassifier(X, W, b):\n",
    "    print(X.shape)\n",
    "    print(W.shape)\n",
    "    print(b.shape)\n",
    "    P = np.shape(X)\n",
    "    W *= X\n",
    "    W += b\n",
    "    P = softmax(s)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59  43  50 ... 140  84  72]\n",
      " [154 126 105 ... 139 142 144]\n",
      " [255 253 253 ...  83  83  84]\n",
      " ...\n",
      " [ 71  60  74 ...  68  69  68]\n",
      " [250 254 211 ... 215 255 254]\n",
      " [ 62  61  60 ... 130 130 131]]\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "X_train, Y_train, y_test = ReadData('data_batch_1')\n",
    "X_val_train, Y_val_train, y_val_test = ReadData('data_batch_2')\n",
    "X_test_train, Y_test_train, y_test_test = ReadData('test_batch')\n",
    "\n",
    "# Gets mean and std of training data\n",
    "X_mean, X_std = GetMeanAndStd(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all data w.r.t. mean and std of training data\n",
    "X_train_normalized, X_val_train_normalized, X_test_train_normalized = Normalize(X_train, X_val_train, X_test_train, X_mean, X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.51405608e-03 -9.30387699e-03 -9.79604602e-03 ... -3.63667128e-03\n",
      "  -6.05096676e-03 -1.11976376e-02]\n",
      " [-1.54664004e-02 -4.03341544e-03 -2.96410761e-03 ... -4.54523792e-03\n",
      "  -7.94548650e-03  3.23887876e-03]\n",
      " [-9.32536534e-04 -2.45234102e-03 -6.81513512e-03 ...  1.54116413e-02\n",
      "  -1.95717750e-03 -3.48180863e-04]\n",
      " ...\n",
      " [-6.83818096e-03 -4.88631203e-03 -2.53255356e-02 ... -6.89556966e-03\n",
      "   1.36262393e-03  6.13256852e-03]\n",
      " [ 1.18903512e-02  1.76239490e-02 -7.96005230e-05 ... -5.69642302e-03\n",
      "  -1.05770263e-02  3.24540891e-03]\n",
      " [ 1.32733525e-02  2.02983616e-02 -2.82670911e-03 ...  1.21204061e-02\n",
      "   4.05636805e-03  1.83974725e-02]]\n",
      "10000\n",
      "[ 0.00710517 -0.00956444  0.00750355 ...  0.0119481   0.00831068\n",
      " -0.0067609 ]\n"
     ]
    }
   ],
   "source": [
    "# Create model params W and b\n",
    "# W = Weight, b = bias\n",
    "W, b = GetWeightAndBias(X_train_normalized, Y_train)\n",
    "\n",
    "print(W)\n",
    "print(b.size)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99022072 -1.21342601 -1.13375625 ...  0.39523272 -0.45995317\n",
      " -0.64501523]\n",
      "(10000, 3072)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10000,3072) (10000,) (10000,3072) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-977994cc77bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluateClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-038fc87e8dcc>\u001b[0m in \u001b[0;36mEvaluateClassifier\u001b[0;34m(X, W, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,3072) (10000,) (10000,3072) "
     ]
    }
   ],
   "source": [
    "print(X_train_normalized[0])\n",
    "P = EvaluateClassifier(X_train_normalized, W, b)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
